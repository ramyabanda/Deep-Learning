# -*- coding: utf-8 -*-
"""Hw02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mntoG_L82vW_IdXJzA97pDe6XULjCVqS
"""

import torch
import numpy as np
import torchvision
import torchvision.transforms as tvt
dataroot = "Users/ramyabanda/Desktop/695/HW/HW2/cifar-10-batches-py"

transform = tvt.Compose([tvt.ToTensor(), tvt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_data_loc = torchvision.datasets.CIFAR10(root=dataroot, train=True,download=True, transform=transform)
test_data_loc = torchvision.datasets.CIFAR10(root=dataroot, train=False,download=True,transform=transform)

train_data=[]
train_targets=[]
test_data=[]
test_targets=[]
cat_label = [1,0]
dog_label = [0,1]
#print(len(train_data_loc.data))
#print(len(train_data_loc.targets))
for i in range(len(train_data_loc.targets)):
  if(train_data_loc.targets[i]==3):
    train_data.append(train_data_loc.data[i])
    train_targets.append(3)
  elif(train_data_loc.targets[i]==5):
    train_data.append(train_data_loc.data[i])
    train_targets.append(5)
train_data_loc.data = train_data
train_data_loc.targets = train_targets

for i in range(len(test_data_loc)):
  if(test_data_loc.targets[i]==3):
    test_data.append(test_data_loc.data[i])
    test_targets.append(3)
  elif(test_data_loc.targets[i]==5):
    test_data.append(test_data_loc.data[i])
    test_targets.append(5)
test_data_loc.data = test_data
test_data_loc.targets = test_targets

trainloader = torch.utils.data.DataLoader(train_data_loc, batch_size=5,shuffle=True, num_workers=2)
testloader = torch.utils.data.DataLoader(test_data_loc, batch_size=5, shuffle=False, num_workers=2)

D_in, H1, H2, D_out = 3*32*32, 1000, 256, 2
dtype = torch.float
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
w1 = torch.randn(D_in, H1, device=device, dtype=dtype)
w2 = torch.randn(H1, H2, device=device, dtype=dtype)
w3 = torch.randn(H2, D_out, device=device, dtype=dtype)
f = open("output.txt", 'w')

batch_size = 5
learning_rate = 1e-9
y=np.zeros((5,2))
for t in range(100):
  for i, data in enumerate(trainloader):
    inputs, labels = data
    inputs = inputs.to(device)
    labels = labels.to(device)
    y=np.zeros((5,2))
    x = inputs.view(inputs.size(0), -1)
    h1 = x.mm(w1) 
    h1_relu = h1.clamp(min=0)
    h2 = h1_relu.mm(w2)
    h2_relu = h2.clamp(min=0)
    y_pred = h2_relu.mm(w3)
    #print(y_pred.shape)
    for j in range(batch_size):
      if (labels[j]==3):
        y[j,:] = cat_label
      elif (labels[j]==5):
        y[j,:] = dog_label
    y = torch.FloatTensor(y)
    #print(y_pred.shape)
    #print(y.shape)
    y = y.to(device)
    loss = (y_pred - y).pow(2).sum().item()
    if(i==1):
      print("Epoch ", t,":", loss)
      f.write("Epoch {}: {}\n".format(t, loss))
    y_error = y_pred - y
    grad_w3 = h2_relu.t().mm(2 * y_error) 
    h2_error = 2.0 * y_error.mm(w3.t()) 
    h2_error[h2 < 0] = 0
    grad_w2 = h1_relu.t().mm(2 * h2_error)
    h1_error = 2.0 * h2_error.mm(w2.t()) 
    h1_error[h1 < 0] = 0
    grad_w1 = x.t().mm(2 * h1_error)
    w1 -= learning_rate * grad_w1
    w2 -= learning_rate * grad_w2
    w3 -= learning_rate * grad_w3 

positive = 0
y=np.zeros((5,2))
cat_label = np.asarray(cat_label)
dog_label = np.asarray(dog_label)
for i, data in enumerate(testloader):
  inputs, labels = data
  inputs = inputs.to(device)
  labels = labels.to(device)
  y=np.zeros((5,2))
  x = inputs.view(inputs.size(0), -1)
  h1 = x.mm(w1) 
  h1_relu = h1.clamp(min=0)
  h2 = h1_relu.mm(w2)
  h2_relu = h2.clamp(min=0)
  y_pred = h2_relu.mm(w3)
  for j in range(batch_size):
    if (labels[j]==3):
      y[j,:] = cat_label
    elif (labels[j]==5):
      y[j,:] = dog_label
  #Checking for correct predictions  
  for k in range(batch_size):  
    if( y_pred[k,0] > y_pred[k,1] and np.array_equal(y[k,:], cat_label) ):
      positive+=1
    elif( y_pred[k,0] < y_pred[k,1] and np.array_equal(y[k,:], dog_label)):
      positive+=1
      
accuracy = (positive/len(test_data_loc.data))*100
print("\nTest accuracy: ",accuracy)
f.write("\nTest accuracy: {}%".format(accuracy))
f.close()