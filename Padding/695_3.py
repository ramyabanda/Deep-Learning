# -*- coding: utf-8 -*-
"""695_HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fqoiG8pDIAeyZ1RQ5SnKYXZlMbAepcKQ
"""

!nvidia-smi

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as tvt
import numpy as np

torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

transform = tvt.Compose([tvt.ToTensor(), tvt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
dataroot = "Users/ramyabanda/Desktop/695/HW/HW2/cifar-10-batches-py"

train_data_loc = torchvision.datasets.CIFAR10(root=dataroot, train=True,download=True, transform=transform)
test_data_loc = torchvision.datasets.CIFAR10(root=dataroot, train=False,download=True,transform=transform)

train_data_loader = torch.utils.data.DataLoader(train_data_loc, batch_size=4,shuffle=True, num_workers=2)
test_data_loader = torch.utils.data.DataLoader(test_data_loc, batch_size=4, shuffle=False, num_workers=2)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
epochs = 1
batch_size = 4

def prog(): 

  #Model with no padding for 1st layer and no 2nd conv layer
  class TemplateNet(nn.Module): 
    def __init__(self):
      super(TemplateNet, self).__init__()
      self.conv1 = nn.Conv2d(3, 128, 3, padding=0) ## (A)
      #self.conv2 = nn.Conv2d(128, 128, 3) ## (B)
      self.pool = nn.MaxPool2d(2, 2)
      self.fc1 = nn.Linear(28800, 1000) ## (C)
      self.fc2 = nn.Linear(1000, 10)
    def forward(self, x):
      x = self.pool(F.relu(self.conv1(x)))
      #x = self.pool(F.relu(self.conv2(x))) ## (D)
      x = x.view(-1, 28800) ## (E)
      x = F.relu(self.fc1(x))
      x = self.fc2(x)
      return x

  #Model with no padding in 1st layer and has 2nd conv layer
  class TemplateNet1(nn.Module): 
    def __init__(self):
      super(TemplateNet1, self).__init__()
      self.conv1 = nn.Conv2d(3, 128, 3, padding=0) ## (A)
      self.conv2 = nn.Conv2d(128, 128, 3) ## (B)
      self.pool = nn.MaxPool2d(2, 2)
      self.fc1 = nn.Linear(4608, 1000) ## (C)
      self.fc2 = nn.Linear(1000, 10)
    def forward(self, x):
      x = self.pool(F.relu(self.conv1(x)))
      x = self.pool(F.relu(self.conv2(x))) ## (D)
      x = x.view(-1, 4608) ## (E)
      x = F.relu(self.fc1(x))
      x = self.fc2(x)
      return x

  #Model with padding in 1st conv layer and has 2nd conv layer
  class TemplateNet2(nn.Module): 
    def __init__(self):
      super(TemplateNet2, self).__init__()
      self.conv1 = nn.Conv2d(3, 128, 3, padding=1) ## (A)
      self.conv2 = nn.Conv2d(128, 128, 3) ## (B)
      self.pool = nn.MaxPool2d(2, 2)
      self.fc1 = nn.Linear(6272, 1000) ## (C)
      self.fc2 = nn.Linear(1000, 10)
    def forward(self, x):
      x = self.pool(F.relu(self.conv1(x)))
      x = self.pool(F.relu(self.conv2(x))) ## (D)
      x = x.view(-1, 6272) ## (E)
      x = F.relu(self.fc1(x))
      x = self.fc2(x)
      return x

  #Training for 3 different models
  def run_code_for_training(net):
    net = net.to(device)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)
    for epoch in range(epochs):
      running_loss = 0.0
      for i, data in enumerate(train_data_loader):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if (i+1) % 12000  == 0:
          print("[epoch:%d, batch:%5d] loss: %.3f" % (epoch + 1, i + 1, running_loss / float(2000)))
          f.write("[epoch:%d, batch:%5d] loss: %.3f\n" % (epoch + 1, i + 1, running_loss / float(2000)))
        if i % 2000 == 1999:
          running_loss = 0.0

  #Testing and Confusion Matrix
  def run_code_for_testing(net):
    net = net.to(device)
    conf_matrix = torch.zeros([10,10])
    for epoch in range(epochs):
      for i, data in enumerate(test_data_loader):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        outputs = net(inputs)
        pred_label = outputs.max(1)
        for j in range(batch_size):
          conf_matrix[pred_label.indices[j],labels[j]]+=1
    print(conf_matrix)
    f.write(str(conf_matrix)) 

  #Instance Creation
  net = TemplateNet()
  net1 = TemplateNet1()
  net2 = TemplateNet2()

  #File Creation
  f = open("output.txt", 'w')

  #Calling functions
  run_code_for_training(net)
  run_code_for_training(net1)
  run_code_for_training(net2)
  run_code_for_testing(net2)

if __name__ == '__main__':
  prog()